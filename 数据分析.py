import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.io as pio
from datetime import datetime
import re
import numpy as np
from typing import Dict, List, Optional
import gc  # åƒåœ¾å›æ”¶
from streamlit.runtime.caching import cache_data

# ---------------------- å…¨å±€é…ç½® & æ€§èƒ½ä¼˜åŒ–åŸºç¡€ ----------------------
# è®¾ç½®ä¸­æ–‡æ˜¾ç¤º
pio.renderers.default = "browser"
px.defaults.template = "plotly_white"
px.defaults.color_continuous_scale = px.colors.sequential.Reds

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="é«˜æ€§èƒ½å¤šæ–‡ä»¶+è‡ªç„¶è¯­è¨€æ•°æ®åˆ†æå·¥å…·",
    page_icon="ğŸ“Š",
    layout="wide"
)

# æ€§èƒ½å‚æ•°é…ç½®
MAX_PREVIEW_ROWS = 100  # é¢„è§ˆæœ€å¤§è¡Œæ•°
MAX_CHART_POINTS = 5000  # å›¾è¡¨æœ€å¤§æ•°æ®ç‚¹
CHUNK_SIZE = 10000       # åˆ†å—è¯»å–å¤§å°
CACHE_TTL = 3600         # ç¼“å­˜æœ‰æ•ˆæœŸï¼ˆç§’ï¼‰

# ---------------------- ç¼“å­˜ & é«˜æ€§èƒ½å‡½æ•° ----------------------
@cache_data(ttl=CACHE_TTL)  # ç¼“å­˜æ•°æ®å¤„ç†ç»“æœ
def load_and_clean_data(uploaded_files: List) -> Optional[pd.DataFrame]:
    """
    é«˜æ€§èƒ½åŠ è½½å¹¶æ¸…ç†å¤šæ–‡ä»¶æ•°æ®
    - åˆ†å—è¯»å–
    - æ•°æ®ç±»å‹ä¼˜åŒ–
    - ç¼ºå¤±å€¼/é‡å¤å€¼å¤„ç†
    """
    df_list = []
    for file in uploaded_files:
        try:
            # åˆ†å—è¯»å–å¤§æ–‡ä»¶
            if file.size > 10 * 1024 * 1024:  # å¤§äº10MBçš„æ–‡ä»¶åˆ†å—
                if file.name.endswith(".xlsx"):
                    chunks = pd.read_excel(file, chunksize=CHUNK_SIZE)
                else:
                    chunks = pd.read_csv(file, chunksize=CHUNK_SIZE)
                
                temp_df = pd.concat(chunks, ignore_index=True)
            else:  # å°æ–‡ä»¶ç›´æ¥è¯»å–
                if file.name.endswith(".xlsx"):
                    temp_df = pd.read_excel(file)
                else:
                    temp_df = pd.read_csv(file)
            
            # æ·»åŠ æ¥æºæ–‡ä»¶åˆ—
            temp_df["æ¥æºæ–‡ä»¶"] = file.name
            
            # æ•°æ®ç±»å‹ä¼˜åŒ–ï¼ˆæ ¸å¿ƒï¼å‡å°‘å†…å­˜å ç”¨ï¼‰
            temp_df = optimize_dtypes(temp_df)
            
            # é¢„å¤„ç†ï¼šç¼ºå¤±å€¼/é‡å¤å€¼
            temp_df = preprocess_data(temp_df)
            
            df_list.append(temp_df)
            
            # é‡Šæ”¾å†…å­˜
            del temp_df
            gc.collect()
            
        except Exception as e:
            st.warning(f"âš ï¸ æ–‡ä»¶ {file.name} è¯»å–å¤±è´¥ï¼š{str(e)}")
            continue
    
    if not df_list:
        return None
    
    # åˆå¹¶æ•°æ®å¹¶å†æ¬¡ä¼˜åŒ–
    df = pd.concat(df_list, ignore_index=True)
    df = optimize_dtypes(df)
    
    # é‡Šæ”¾ä¸´æ—¶åˆ—è¡¨å†…å­˜
    del df_list
    gc.collect()
    
    return df

def optimize_dtypes(df: pd.DataFrame) -> pd.DataFrame:
    """ä¼˜åŒ–æ•°æ®ç±»å‹ï¼Œå‡å°‘å†…å­˜å ç”¨"""
    df_optimized = df.copy()
    
    # æ•°å€¼åˆ—ä¼˜åŒ–ï¼šint64â†’int32ï¼Œfloat64â†’float32ï¼ˆæ— ç²¾åº¦æŸå¤±æ—¶ï¼‰
    for col in df_optimized.select_dtypes(include=["int64"]).columns:
        if df_optimized[col].max() <= np.iinfo(np.int32).max and df_optimized[col].min() >= np.iinfo(np.int32).min:
            df_optimized[col] = df_optimized[col].astype(np.int32)
    
    for col in df_optimized.select_dtypes(include=["float64"]).columns:
        df_optimized[col] = df_optimized[col].astype(np.float32)
    
    # å­—ç¬¦ä¸²åˆ—ä¼˜åŒ–ï¼šé«˜é¢‘é‡å¤å€¼â†’category
    for col in df_optimized.select_dtypes(include=["object"]).columns:
        if col != "æ¥æºæ–‡ä»¶" and len(df_optimized[col].unique()) / len(df_optimized[col]) < 0.1:  # å”¯ä¸€å€¼å æ¯”<10%
            df_optimized[col] = df_optimized[col].astype("category")
    
    # æ—¥æœŸåˆ—è‡ªåŠ¨è¯†åˆ«
    for col in df_optimized.columns:
        if col.lower() in ["æ—¥æœŸ", "æ—¶é—´", "date", "time"] and not pd.api.types.is_datetime64_any_dtype(df_optimized[col]):
            try:
                df_optimized[col] = pd.to_datetime(df_optimized[col], errors="coerce")
            except:
                pass
    
    return df_optimized

def preprocess_data(df: pd.DataFrame) -> pd.DataFrame:
    """é¢„å¤„ç†ï¼šç¼ºå¤±å€¼/é‡å¤å€¼å¤„ç†"""
    # åˆ é™¤å…¨ç©ºè¡Œ/åˆ—
    df = df.dropna(how="all", axis=0).dropna(how="all", axis=1)
    
    # åˆ é™¤é‡å¤è¡Œ
    df = df.drop_duplicates()
    
    # æ•°å€¼åˆ—ç¼ºå¤±å€¼å¡«å……ï¼ˆç”¨ä¸­ä½æ•°ï¼Œé¿å…å‡å€¼å—å¼‚å¸¸å€¼å½±å“ï¼‰
    for col in df.select_dtypes(include=["int32", "float32"]).columns:
        df[col] = df[col].fillna(df[col].median())
    
    return df

@cache_data(ttl=CACHE_TTL)
def parse_prompt_optimized(prompt: str, numeric_cols: List, category_cols: List, date_cols: List) -> Dict:
    """ä¼˜åŒ–çš„æŒ‡ä»¤è§£æå‡½æ•°ï¼ˆç¼“å­˜è§£æç»“æœï¼‰"""
    # æå–æŒ‡æ ‡ï¼ˆæ•°å€¼åˆ—ï¼‰
    target = None
    for col in numeric_cols:
        if col in prompt:
            target = col
            break
    
    # æå–åˆ†ç»„ç»´åº¦
    group = None
    for col in category_cols + date_cols + ["æ¥æºæ–‡ä»¶"]:
        if col in prompt:
            group = col
            break
    
    # æå–å›¾è¡¨ç±»å‹
    chart_map = {
        "æŸ±çŠ¶å›¾": "bar", "æŠ˜çº¿å›¾": "line", "é¥¼å›¾": "pie",
        "æ•£ç‚¹å›¾": "scatter", "ç®±çº¿å›¾": "box"
    }
    chart = None
    for key, val in chart_map.items():
        if key in prompt:
            chart = val
            break
    
    # æå–ç»Ÿè®¡ç±»å‹
    stat_map = {
        "æ€»å’Œ": "sum", "å¹³å‡å€¼": "mean", "å‡å€¼": "mean",
        "ä¸­ä½æ•°": "median", "æœ€å¤§å€¼": "max", "æœ€å°å€¼": "min",
        "æ•°é‡": "count", "è®¡æ•°": "count"
    }
    stat = "sum"
    for key, val in stat_map.items():
        if key in prompt:
            stat = val
            break
    
    # æå–ç­›é€‰æ¡ä»¶ï¼ˆå‘é‡åŒ–æ­£åˆ™åŒ¹é…ï¼‰
    filters = []
    # æ—¥æœŸç­›é€‰
    for col in date_cols:
        if col in prompt:
            year_match = re.search(r"(\d{4})å¹´", prompt)
            if year_match:
                filters.append((col, "year", int(year_match.group(1))))
            month_match = re.search(r"(\d{1,2})æœˆ", prompt)
            if month_match:
                filters.append((col, "month", int(month_match.group(1))))
            break
    
    # TopN/BottomNç­›é€‰
    top_match = re.search(r"æœ€é«˜(\d+)ä¸ª", prompt)
    if top_match:
        filters.append(("top_n", int(top_match.group(1))))
    bottom_match = re.search(r"æœ€ä½(\d+)ä¸ª", prompt)
    if bottom_match:
        filters.append(("bottom_n", int(bottom_match.group(1))))
    
    return {
        "target": target,
        "group": group,
        "chart": chart,
        "stat": stat,
        "filters": filters
    }

def apply_filters_optimized(df: pd.DataFrame, filters: List, target_col: str) -> pd.DataFrame:
    """ä¼˜åŒ–çš„ç­›é€‰å‡½æ•°ï¼ˆå…ˆç­›é€‰åè®¡ç®—ï¼Œå‘é‡åŒ–æ“ä½œï¼‰"""
    filtered_df = df.copy()
    
    for filt in filters:
        if isinstance(filt, tuple):
            col, filt_type, val = filt
            if filt_type == "year":
                filtered_df = filtered_df[filtered_df[col].dt.year == val]
            elif filt_type == "month":
                filtered_df = filtered_df[filtered_df[col].dt.month == val]
        elif filt[0] == "top_n":
            n = filt[1]
            filtered_df = filtered_df.nlargest(n, target_col)
        elif filt[0] == "bottom_n":
            n = filt[1]
            filtered_df = filtered_df.nsmallest(n, target_col)
    
    # é™åˆ¶æœ€å¤§æ•°æ®é‡ï¼ˆé¿å…å›¾è¡¨å¡é¡¿ï¼‰
    if len(filtered_df) > MAX_CHART_POINTS:
        filtered_df = filtered_df.sample(n=MAX_CHART_POINTS, random_state=42)
    
    return filtered_df

# ---------------------- ä¸»ç•Œé¢é€»è¾‘ ----------------------
def main():
    st.title("ğŸ“Š é«˜æ€§èƒ½å¤šæ–‡ä»¶ + è‡ªç„¶è¯­è¨€æŒ‡ä»¤æ•°æ®åˆ†æåº”ç”¨")
    st.divider()
    
    # ç¬¬ä¸€æ­¥ï¼šæ‰¹é‡ä¸Šä¼ æ•°æ®
    st.subheader("1. æ‰¹é‡ä¸Šä¼ æ•°æ®æ–‡ä»¶")
    uploaded_files = st.file_uploader(
        "æ”¯æŒåŒæ—¶ä¸Šä¼ å¤šä¸ªExcel(.xlsx) / CSV(.csv)æ ¼å¼æ–‡ä»¶ï¼ˆæ”¯æŒ10ä¸‡è¡Œ+å¤§æ–‡ä»¶ï¼‰",
        type=["xlsx", "csv"],
        accept_multiple_files=True,
        help="æ‰€æœ‰æ–‡ä»¶éœ€åŒ…å«ç›¸åŒè¡¨å¤´ï¼Œæ¯”å¦‚ï¼šæ—¥æœŸã€åœ°åŒºã€äº§å“ã€é”€å”®é¢ã€åˆ©æ¶¦ç­‰"
    )
    
    if uploaded_files:
        with st.spinner("ğŸ“¥ æ­£åœ¨åŠ è½½å¹¶ä¼˜åŒ–æ•°æ®..."):
            df = load_and_clean_data(uploaded_files)
        
        if df is None:
            st.error("âŒ æ‰€æœ‰æ–‡ä»¶è¯»å–å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®")
            return
        
        # æ•°æ®æ¦‚è§ˆï¼ˆè½»é‡åŒ–é¢„è§ˆï¼‰
        st.success(f"âœ… æˆåŠŸåˆå¹¶ {len(uploaded_files)} ä¸ªæ–‡ä»¶ï¼Œå…± {df.shape[0]:,} è¡Œæ•°æ®ï¼")
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("æ€»è¡Œæ•°", f"{df.shape[0]:,}")
        with col2:
            st.metric("æ€»åˆ—æ•°", df.shape[1])
        with col3:
            st.metric("ç¼ºå¤±å€¼æ€»æ•°", df.isnull().sum().sum())
        with col4:
            mem_usage = df.memory_usage(deep=True).sum() / 1024 / 1024
            st.metric("å†…å­˜å ç”¨", f"{mem_usage:.2f} MB")
        
        # æŠ½æ ·é¢„è§ˆï¼ˆé¿å…å…¨é‡åŠ è½½ï¼‰
        st.subheader("2. æ•°æ®æŠ½æ ·é¢„è§ˆï¼ˆå‰100è¡Œï¼‰")
        preview_df = df.head(MAX_PREVIEW_ROWS)
        st.dataframe(preview_df, use_container_width=True)
        
        st.divider()
        
        # ç¬¬äºŒæ­¥ï¼šè‡ªç„¶è¯­è¨€æŒ‡ä»¤è¾“å…¥
        st.subheader("3. è¾“å…¥ä½ çš„åˆ†æè¦æ±‚ï¼ˆè‡ªç„¶è¯­è¨€ï¼‰")
        st.info("ğŸ’¡ ç¤ºä¾‹ï¼šè®¡ç®—å„åœ°åŒºé”€å”®é¢æ€»å’Œå¹¶ç”ŸæˆæŸ±çŠ¶å›¾ï¼›æ‰¾å‡º2025å¹´1æœˆåˆ©æ¶¦æœ€é«˜çš„3ä¸ªäº§å“ï¼›æŒ‰æœˆä»½ç»Ÿè®¡é”€å”®é¢è¶‹åŠ¿å¹¶ç”ŸæˆæŠ˜çº¿å›¾")
        
        # æå–åˆ—ååˆ†ç±»ï¼ˆåŸºäºä¼˜åŒ–åçš„æ•°æ®ï¼‰
        numeric_cols = df.select_dtypes(include=["int32", "float32", "int64", "float64"]).columns.tolist()
        category_cols = df.select_dtypes(include=["category", "object"]).columns.tolist()
        date_cols = df.select_dtypes(include=["datetime64"]).columns.tolist()
        
        # æŒ‡ä»¤è¾“å…¥
        user_prompt = st.text_area(
            "è¯·è¾“å…¥ä½ çš„åˆ†æéœ€æ±‚",
            height=100,
            placeholder="ä¾‹å¦‚ï¼šè®¡ç®—å„åœ°åŒºé”€å”®é¢æ€»å’Œå¹¶ç”ŸæˆæŸ±çŠ¶å›¾ï¼›æ‰¾å‡º2025å¹´1æœˆåˆ©æ¶¦æœ€é«˜çš„3ä¸ªäº§å“"
        )
        
        # æ‰§è¡Œåˆ†æ
        if st.button("ğŸ“Š æ‰§è¡Œåˆ†æ", type="primary") and user_prompt:
            with st.spinner("ğŸ” æ­£åœ¨è§£ææŒ‡ä»¤å¹¶åˆ†ææ•°æ®..."):
                # è§£ææŒ‡ä»¤ï¼ˆç¼“å­˜ç»“æœï¼‰
                parsed = parse_prompt_optimized(user_prompt, numeric_cols, category_cols, date_cols)
                target_col = parsed["target"]
                group_col = parsed["group"]
                chart_type = parsed["chart"]
                stat_type = parsed["stat"]
                filters = parsed["filters"]
                
                # å‚æ•°æ ¡éªŒï¼ˆæå‰ç»ˆæ­¢æ— æ•ˆè®¡ç®—ï¼‰
                if not target_col:
                    st.error("âŒ æœªè¯†åˆ«åˆ°åˆ†ææŒ‡æ ‡ï¼Œè¯·ç¡®ä¿è¾“å…¥ä¸­åŒ…å«æ•°å€¼åˆ—åï¼ˆå¦‚é”€å”®é¢ã€åˆ©æ¶¦ç­‰ï¼‰")
                    return
                if not group_col:
                    st.error("âŒ æœªè¯†åˆ«åˆ°åˆ†ç»„ç»´åº¦ï¼Œè¯·ç¡®ä¿è¾“å…¥ä¸­åŒ…å«åˆ†ç±»/æ—¥æœŸåˆ—åï¼ˆå¦‚åœ°åŒºã€æ—¥æœŸç­‰ï¼‰")
                    return
                
                # åº”ç”¨ç­›é€‰ï¼ˆå…ˆç­›é€‰åè®¡ç®—ï¼Œå‡å°‘è®¡ç®—é‡ï¼‰
                filtered_df = apply_filters_optimized(df, filters, target_col)
                
                # æ‰¹é‡èšåˆè®¡ç®—ï¼ˆä¸€æ¬¡groupbyå®Œæˆï¼Œé¿å…å¤šæ¬¡è®¡ç®—ï¼‰
                stats_df = filtered_df.groupby(group_col)[target_col].agg([
                    "sum", "mean", "median", "max", "min", "count"
                ]).round(2).reset_index()
                
                # æå–éœ€è¦çš„ç»Ÿè®¡å€¼
                result_df = stats_df[[group_col, stat_type]].rename(columns={stat_type: target_col})
                
                # ç”Ÿæˆè½»é‡åŒ–å›¾è¡¨
                fig = None
                if chart_type:
                    # é™åˆ¶å›¾è¡¨æ•°æ®ç‚¹
                    chart_df = result_df.head(MAX_CHART_POINTS)
                    
                    if chart_type == "bar":
                        fig = px.bar(chart_df, x=group_col, y=target_col, 
                                     title=f"{group_col} - {target_col} {stat_type} æŸ±çŠ¶å›¾", 
                                     text_auto=True, height=500)
                    elif chart_type == "line":
                        fig = px.line(chart_df, x=group_col, y=target_col, 
                                      title=f"{group_col} - {target_col} {stat_type} è¶‹åŠ¿å›¾", 
                                      markers=True, height=500)
                    elif chart_type == "pie":
                        fig = px.pie(chart_df, values=target_col, names=group_col, 
                                     title=f"{group_col} - {target_col} {stat_type} å æ¯”å›¾", 
                                     hole=0.3, height=500)
                    elif chart_type == "scatter":
                        fig = px.scatter(filtered_df.head(MAX_CHART_POINTS), x=group_col, y=target_col, 
                                         title=f"{group_col} - {target_col} æ•£ç‚¹å›¾", 
                                         color=group_col, height=500)
                    elif chart_type == "box":
                        fig = px.box(filtered_df.head(MAX_CHART_POINTS), x=group_col, y=target_col, 
                                     title=f"{group_col} - {target_col} ç®±çº¿å›¾", height=500)
                
                # å±•ç¤ºç»“æœ
                st.divider()
                st.subheader("4. åˆ†æç»“æœ")
                
                # è¡¨æ ¼ç»“æœ
                st.dataframe(result_df, use_container_width=True)
                
                # å›¾è¡¨ç»“æœ
                if fig:
                    fig.update_layout(xaxis_title=group_col, yaxis_title=target_col)
                    st.plotly_chart(fig, use_container_width=True)
                
                # å¯¼å‡ºç»“æœï¼ˆè½»é‡åŒ–ï¼‰
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                export_filename = f"åˆ†æç»“æœ_{timestamp}.xlsx"
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½åˆ†æç»“æœï¼ˆExcelï¼‰",
                    data=result_df.to_excel(index=False, engine="openpyxl"),
                    file_name=export_filename,
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
                
                # é‡Šæ”¾ä¸´æ—¶æ•°æ®å†…å­˜
                del filtered_df, stats_df, result_df
                gc.collect()
    
    else:
        # æœªä¸Šä¼ æ–‡ä»¶æç¤º
        st.info("ğŸ’¡ è¯·æ‰¹é‡ä¸Šä¼ Excel/CSVæ•°æ®æ–‡ä»¶ï¼ˆæ”¯æŒ10ä¸‡è¡Œ+å¤§æ–‡ä»¶ï¼‰ï¼Œå³å¯å¼€å§‹é«˜æ€§èƒ½æ•°æ®åˆ†æ")
        with st.expander("æŸ¥çœ‹ç¤ºä¾‹æ•°æ®æ ¼å¼"):
            sample_data = pd.DataFrame({
                "æ—¥æœŸ": pd.date_range(start="2025-01-01", periods=10),
                "åœ°åŒº": ["åä¸œ", "ååŒ—", "åå—"] * 3 + ["åä¸œ"],
                "äº§å“ç±»åˆ«": ["ç”µå­äº§å“", "æ—¥ç”¨å“", "é£Ÿå“"] * 3 + ["ç”µå­äº§å“"],
                "é”€å”®é¢": [12000, 8000, 5000, 15000, 9000, 6000, 13000, 7000, 4500, 14000],
                "åˆ©æ¶¦": [2400, 1600, 1000, 3000, 1800, 1200, 2600, 1400, 900, 2800],
                "æ¥æºæ–‡ä»¶": ["æ–‡ä»¶1.xlsx"] * 5 + ["æ–‡ä»¶2.xlsx"] * 5
            })
            st.dataframe(sample_data, use_container_width=True)

if __name__ == "__main__":
    main()
